{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "1. Multilayer Perceptron - MNIST Handwritten Numbers\n",
    "2. Convolutional Neural Networks - \n",
    "3. Recurrent Neural Networks - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron\n",
    "\n",
    "In the end we get 98% accuracy. Pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0223453e4375>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.0005  # how quickly to learn\n",
    "training_epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "n_classes = 10  # MNIST total classes (0 - 9 digits)\n",
    "n_samples = mnist.train.num_examples  # (how many images)\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape is 28x28)\n",
    "\n",
    "n_hidden_1 = 512  # 1st layer number of neurons\n",
    "n_hidden_2 = 256  # 2nd layer number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):#, keep_prob):\n",
    "    '''\n",
    "    x: Placeholder for data input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dictionary of bias values\n",
    "    '''\n",
    "    # First hidden layer with RELU activation\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # RELU(X * W + B) = RELU -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "     \n",
    "\n",
    "    # Second hidden layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    # Output layer\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x: Placeholder for data input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dictionary of bias values\n",
    "    '''\n",
    "    # First hidden layer with dropout\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second hidden layer with dropout\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    # Output layer\n",
    "    out_layer = tf.sigmoid(tf.matmul(layer_2, weights['out']) + biases['out'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: cost=64.1766\n",
      "Epoch 2: cost=46.1122\n",
      "Epoch 3: cost=33.3201\n",
      "Epoch 4: cost=24.0972\n",
      "Epoch 5: cost=17.4217\n",
      "Epoch 6: cost=12.5988\n",
      "Epoch 7: cost=9.1359\n",
      "Epoch 8: cost=6.6735\n",
      "Epoch 9: cost=4.9475\n",
      "Epoch 10: cost=3.7571\n",
      "Epoch 11: cost=2.9502\n",
      "Epoch 12: cost=2.4115\n",
      "Epoch 13: cost=2.0568\n",
      "Epoch 14: cost=1.8264\n",
      "Epoch 15: cost=1.6789\n",
      "Epoch 16: cost=1.5868\n",
      "Epoch 17: cost=1.5305\n",
      "Epoch 18: cost=1.4981\n",
      "Epoch 19: cost=1.4804\n",
      "Epoch 20: cost=1.4721\n",
      "Epoch 21: cost=1.4680\n",
      "Epoch 22: cost=1.4662\n",
      "Epoch 23: cost=1.4655\n",
      "Epoch 24: cost=1.4654\n",
      "Epoch 25: cost=1.4650\n",
      "Model has completed 25 Epochs of training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {\n",
    "    'h1':  tf.Variable(tf.random_normal([n_input,    n_hidden_1], stddev=(1/tf.sqrt(float(n_input))))),\n",
    "    'h2':  tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=(1/tf.sqrt(float(n_input))))),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes],  stddev=(1/tf.sqrt(float(n_input)))))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1':  tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':  tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_classes])\n",
    "\n",
    "# add dropout layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "pred = multilayer_perceptron(x, weights, biases)#, keep_prob)\n",
    "\n",
    "#cost = tf.reduce_mean(\n",
    "#    tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "\n",
    "regularizer_rate = 0.1\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y)) \\\n",
    "        + regularizer_rate*(tf.reduce_sum(tf.square(biases['b1'])) + tf.reduce_sum(tf.square(biases['b2'])))\n",
    "\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# 15 loops as we set training_epochs = 15\n",
    "for epoch in range(training_epochs):\n",
    "    # Cost\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        # Grab the next batch of training data and labels\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Feed dictionary for optimization and loss value\n",
    "        # Returns a tuple, but we only need 'c' the cost\n",
    "        # So we set an underscore as a \"throwaway\"\n",
    "        # Feed a value < 1.0 to keep prob during training\n",
    "        _, c = sess.run([optimiser, cost], feed_dict={\n",
    "                        x: batch_x, y: batch_y, keep_prob: 1})\n",
    "        avg_cost += c/total_batch\n",
    "    print(\"Epoch {}: cost={:.4f}\".format(epoch+1, avg_cost))\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))\n",
    "\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))  # checks if x==y?\n",
    "correct_pred = tf.cast(correct_pred, 'float')\n",
    "accuracy = tf.reduce_mean(correct_pred)\n",
    "# feed a value of 1.0 to keep prob\n",
    "accuracy.eval({x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.98\n",
      "Precision 0.98\n",
      "Recall 0.98\n",
      "f1_score 0.98\n",
      "confusion_matrix\n",
      "[[ 973    0    0    1    1    1    0    1    3    0]\n",
      " [   0 1126    3    1    0    0    2    1    2    0]\n",
      " [   4    2 1004    1    5    1    0    8    6    1]\n",
      " [   0    0    2  987    0    8    1    6    3    3]\n",
      " [   1    0    2    1  964    0    3    1    0   10]\n",
      " [   3    0    0    4    2  876    3    1    2    1]\n",
      " [   4    2    2    1    5    9  932    0    3    0]\n",
      " [   1    4    5    0    1    0    0 1009    2    6]\n",
      " [   5    0    2    1    6    1    1    5  949    4]\n",
      " [   4    2    0    3    7    3    0    7    3  980]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "#metrics\n",
    "y_p = tf.argmax(pred, 1)\n",
    "val_accuracy, y_pred = sess.run([accuracy, y_p], feed_dict={x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0})\n",
    "\n",
    "print(\"validation accuracy:\", val_accuracy)\n",
    "y_true = np.argmax(mnist.test.labels,1)\n",
    "print(\"Precision\", sk.metrics.precision_score(y_true, y_pred, average='micro'))\n",
    "print(\"Recall\", sk.metrics.recall_score(y_true, y_pred, average='micro'))\n",
    "print(\"f1_score\", sk.metrics.f1_score(y_true, y_pred, average='micro'))\n",
    "print(\"confusion_matrix\")\n",
    "print(sk.metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\n",
    "\n",
    "Believe it or not, it is actually pretty simple once it is broken down into steps.\n",
    "\n",
    "\n",
    "Despite the bad humor, <a href=\"https://medium.com/deep-math-machine-learning-ai/chapter-8-0-convolutional-neural-networks-for-deep-learning-364971e34ab2\">this article actually explains it very well.</a>\n",
    "\n",
    "\n",
    "Essentially:\n",
    "\n",
    "`[Apply filter]` > `[Pooling]` > `[Normalize/Activation Function]` > `[Feed into Fully Connected NN]` > `[Update Weights (Back Propagation)]`\n",
    "\n",
    "\n",
    "BUT! Each of the steps above is just a type of layer. They can, in fact, be in any order, and in any orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN With PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Neural net\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural net\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv_layer2 = nn.Conv2d(6, 16, 5)\n",
    "        self.linear_layer1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.linear_layer2 = nn.Linear(120, 10)\n",
    "    # end __init__\n",
    "    \n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = self.conv_layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 4 * 4) # reshape tensor to have (16*4*4) columns and (-1) any number of rows\n",
    "        x = F.relu(self.linear_layer1(x))\n",
    "        x = F.relu(self.linear_layer2(x))\n",
    "        return x\n",
    "    # end forward\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss 0.10710176825523376, train accuracy 96, test accuracy 98\n",
      "Epoch 1, average loss 0.045862600207328796, train accuracy 98, test accuracy 98\n",
      "Epoch 2, average loss 0.038945842534303665, train accuracy 98, test accuracy 98\n",
      "Epoch 3, average loss 0.03852394223213196, train accuracy 98, test accuracy 98\n",
      "Epoch 4, average loss 0.03546438366174698, train accuracy 99, test accuracy 98\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Random seed\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "# Batch size\n",
    "batch_size = 5\n",
    "# Transformation to tensor and normalization\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "# Download the training set\n",
    "trainset = torchvision.datasets.EMNIST(root='./data', split='digits', train=True, download=True, transform=transform)\n",
    "# Training set loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "# Test set\n",
    "testset = torchvision.datasets.EMNIST(root='./data', split='digits', train=False, download=True, transform=transform)\n",
    "# Test set loader\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Function to show images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "# end imshow\n",
    "\n",
    "# Classes\n",
    "classes = ('Zero - 0', \n",
    "           'One - 1', \n",
    "           'Two - 2', \n",
    "           'Three - 3', \n",
    "           'Four - 4', \n",
    "           'Five - 5', \n",
    "           'Size - 6', \n",
    "           'Seven - 7', \n",
    "           'Eight - 8', \n",
    "           'Nine - 9')\n",
    "# Data set as iterator\n",
    "dataiter = iter(trainloader)\n",
    "#Get next batch\n",
    "images, labels = dataiter.next()\n",
    "# N batches\n",
    "n_batches = len(dataiter)\n",
    "# Our neural net, run it on CUDA GPU\n",
    "net = Net()\n",
    "net.cuda()\n",
    "# Objective function is cross-entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Learning rate\n",
    "learning_rate = 0.005\n",
    "# Stochastic gradient descent\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# N iterations\n",
    "n_iterations = 5\n",
    "# List of training and test accuracies\n",
    "train_accuracies = np.zeros(n_iterations)\n",
    "test_accuracies = np.zeros(n_iterations)\n",
    "\n",
    "# Training\n",
    "for epoch in range(n_iterations):\n",
    "    # Average loss during training\n",
    "    average_loss = 0.0\n",
    "    # Data to compute accuracy\n",
    "    total   = 0\n",
    "    success = 0\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "        # To variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        # Put grad to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        outputs = net(inputs)\n",
    "        # Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "        # Add to loss\n",
    "        average_loss += loss.data\n",
    "        # Take the max as predicted\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Add to total\n",
    "        total += labels.size(0)\n",
    "        # Add correctly classified images\n",
    "        success += (predicted == labels.data).sum()\n",
    "    # end for\n",
    "    train_accuracy = 100.0 * success / total\n",
    "\n",
    "    # Test model on test set\n",
    "    success = 0\n",
    "    total = 0\n",
    "    for (inputs, labels) in testloader:\n",
    "        # To variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        # Neural net's outputs\n",
    "        outputs = net(inputs)\n",
    "        # Take the max as predicted\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Add to total\n",
    "        total   += labels.size(0)\n",
    "        # Add correctly classified images\n",
    "        success += (predicted == labels.data).sum()\n",
    "    # end for\n",
    "\n",
    "    # print average loss and accuracies\n",
    "    print(u\"Epoch {}, average loss {}, train accuracy {}, test accuracy {}\".format(\n",
    "        epoch,\n",
    "        average_loss / n_batches,\n",
    "        train_accuracy,\n",
    "        100.0 * success / total\n",
    "    ))\n",
    "\n",
    "    # Save\n",
    "    train_accuracies[epoch] = train_accuracy\n",
    "    test_accuracies[epoch] = 100.0 * success / total\n",
    "# end for\n",
    "\n",
    "plt.plot(np.arange(1, n_iterations+1), train_accuracies)\n",
    "plt.plot(np.arange(1, n_iterations+1), test_accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x179065ff8d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACFCAYAAABL2gNbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBBP4IJOCCGe8P+xsZ6/IT+2JwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig, (ax0,ax1,ax2) = plt.subplots(1,3)\n",
    "\n",
    "ax0.imshow((iter(trainloader).next()[0][0][0]).numpy().T)\n",
    "ax1.imshow((iter(trainloader).next()[0][1][0]).numpy().T)\n",
    "ax2.imshow((iter(trainloader).next()[0][2][0]).numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
